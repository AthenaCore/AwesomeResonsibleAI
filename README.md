[![Awesome](awesome.svg)](https://github.com/AthenaCore/AwesomeResponsibleAI)
[![Maintenance](https://img.shields.io/badge/Maintained%3F-YES-green.svg)](https://github.com/AthenaCore/AwesomeResponsibleAI/graphs/commit-activity)
![GitHub](https://img.shields.io/badge/Release-PROD-yellow.svg)
![GitHub](https://img.shields.io/badge/Languages-MULTI-blue.svg)
![GitHub](https://img.shields.io/badge/License-MIT-lightgrey.svg)
[![GitHub](https://img.shields.io/twitter/follow/athenacoreai.svg?label=Follow)](https://twitter.com/athenacoreai)

# Awesome Responsible AI
A curated list of awesome academic research, books, code of ethics, newsletters, principles, podcast, reports, tools and regulations related to Responsible AI.

## Contents

- [Academic Research](#academic-research)
- [Books](#books)
- [Code of Ethics](#code-of-ethics)
- [Newsletters](#newsletters)
- [Principles](#principles)
- [Podcasts](#podcasts)
- [Reports](#reports)
- [Tools](#tools)
- [Regulations](#regulations)

## Academic Research

### Local post-hoc explanation 

- Efficient Data Representation by Selecting Prototypes with Importance Weights ([Gurumoorthy et al., 2019](https://arxiv.org/abs/1707.01212)) `Amazon Development Center` `IBM Research`
- Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives ([Dhurandhar et al., 2018](https://papers.nips.cc/paper/7340-explanations-based-on-the-missing-towards-contrastive-explanations-with-pertinent-negatives)) `University of Michigan` `IBM Research`
- Contrastive Explanations Method with Monotonic Attribute Functions ([Luss et al., 2019](https://arxiv.org/abs/1905.12698))
- "Why Should I Trust You?": Explaining the Predictions of Any Classifier (LIME) ([Ribeiro et al. 2016](https://arxiv.org/abs/1602.04938),  [Github](https://github.com/marcotcr/lime)) `University of Washington`
- A Unified Approach to Interpreting Model Predictions (SHAP) ([Lundberg, et al. 2017](http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions),  [Github](https://github.com/slundberg/shap)) `University of Washington`

### Local direct explanation

- Teaching AI to Explain its Decisions ([Hind et al., 2019](https://doi.org/10.1145/3306618.3314273)) `IBM Research`
   
### Global direct explanation

- Boolean Decision Rules via Column Generation (Light Edition) ([Dash et al., 2018](https://papers.nips.cc/paper/7716-boolean-decision-rules-via-column-generation)) `IBM Research`
- Generalized Linear Rule Models ([Wei et al., 2019](http://proceedings.mlr.press/v97/wei19a.html)) `IBM Research`

### Global post-hoc explanationÂ 

- Improving Simple Models with Confidence Profiles ([Dhurandhar et al., 2018](https://papers.nips.cc/paper/8231-improving-simple-models-with-confidence-profiles)) `IBM Research`

### Explainability and fairness metrics

- Towards Robust Interpretability with Self-Explaining Neural Networks ([Alvarez-Melis et al., 2018](https://papers.nips.cc/paper/8003-towards-robust-interpretability-with-self-explaining-neural-networks)) `MIT`
- Leveraging Latent Features for Local Explanations ([Luss et al., 2019](https://arxiv.org/abs/1905.12698)) `IBM Research` `University of Michigan`
- [LiFT: A Scalable Framework for Measuring Fairness in ML Applications](https://engineering.linkedin.com/blog/2020/lift-addressing-bias-in-large-scale-ai-applications) ([Vasuvedan et al., 2020](https://arxiv.org/abs/2008.07433)) `LinkedIn`

### Ethical Data Products

- [Building Inclusive Products Through A/B Testing](https://engineering.linkedin.com/blog/2020/building-inclusive-products-through-a-b-testing) ([Saint-Jacques et al, 2020](https://arxiv.org/pdf/2002.05819)) `LinkedIn`

## Books

### Open Access

- Interpretable Machine Learning ([Molnar, C., 2021](https://christophm.github.io/interpretable-ml-book/)) `Interpretability`
- Explanatory Model Analysis ([Biecek et al., 2020](https://ema.drwhy.ai)) `Explicability`

### Commercial / Propietary / Closed Access

- [Trust in Machine Learning](https://www.manning.com/books/trust-in-machine-learning)
- [Interpretable AI](https://www.manning.com/books/interpretable-ai)
- [AI Fairness](https://learning.oreilly.com/library/view/ai-fairness/9781492077664/)
- [Practical Fairness](https://learning.oreilly.com/library/view/practical-fairness/9781492075721/)
- [Hands-On Explainable AI (XAI) with Python](https://www.packtpub.com/product/hands-on-explainable-ai-xai-with-python/9781800208131)
- [AI and the Law](https://learning.oreilly.com/library/view/ai-and-the/9781492091837/)
- [Responsible Machine Learning](https://learning.oreilly.com/library/view/responsible-machine-learning/9781492090878/)
- [Privacy-Preserving Machine Learning](https://www.manning.com/books/privacy-preserving-machine-learning)
- [Human-In-The-Loop Machine Learning: Active Learning and Annotation for Human-Centered AI](https://www.manning.com/books/human-in-the-loop-machine-learning)
- [Interpretable Machine Learning With Python: Learn to Build Interpretable High-Performance Models With Hands-On Real-World Examples](https://www.packtpub.com/product/interpretable-machine-learning-with-python/9781800203907)
- [Responsible AI](https://learning.oreilly.com/library/view/responsible-ai/9781098102425/)

## Code of Ethics
## Newsletters

- [Import AI](https://jack-clark.net)
- [The AI Ethics Brief](https://brief.montrealethics.ai)
- [The Machine Learning Engineer](https://ethical.institute/mle.html) 

## Principles
## Podcasts

## Reports

- [Inferring Concept Drift Without Labeled Data, 2021](https://concept-drift.fastforwardlabs.com) `Drift`
- [Interpretability, Fast Forward Labs, 2020](https://ff06-2020.fastforwardlabs.com) `Interpretability`

## Tools

### Fairness

- [Aequitas' Bias & Fairness Audit Toolkit](http://aequitas.dssg.io/) `Python`
- [Fairlearn](https://fairlearn.org) `Python`
- [fairness](https://cran.r-project.org/web/packages/fairness/) `R`

### Interpretability/Explicability

- [Dalex](https://dalex.drwhy.ai) `Python` `R`
- [eXplainability Toolbox](https://ethical.institute/xai.html) `Python`
- [IBM's AI Explainability 360 Open Source Toolkit](http://aix360.mybluemix.net/) `Python`

### Drift

- [Evidently](https://github.com/evidentlyai/evidently) `Python`
- [drifter](https://cran.r-project.org/web/packages/drifter/) `R`

### Non-active

- [FAT Forensics](https://fat-forensics.org/) (last update 19 May 2020) `Python`

## Regulations

- [Data Protection Laws of the Word](https://www.dlapiperdataprotection.com)

### European Union

- [Ethics Guidelines for Trustworthy AI](https://ec.europa.eu/futurium/en/ai-alliance-consultation) - European Commission document prepared by the High-Level Expert Group on Artificial Intelligence (AI HLEG). 
- [General Data Protection Regulation GDPR](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex%3A32016R0679) - Legal text for the EU GDPR regulation 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC
- [GDPR.EU Guide](https://gdpr.eu/) - A project co-funded by the Horizon 2020 Framework programme of the EU which provides a resource for organisations and individuals researching GDPR, including a library of straightforward and up-to-date information to help organisations achieve GDPR compliance ([Legal Text](https://www.govinfo.gov/content/pkg/USCODE-2012-title5/pdf/USCODE-2012-title5-partI-chap5-subchapII-sec552a.pdf)).
